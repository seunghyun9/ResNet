{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ~\\tensorflow_datasets\\fashion_mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202b17f78f754c1d9bcdca8a0c93873e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14f0788e32a4c8d8e855f228fd99c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6434343c38485692c4b196c9419c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3752ac3e90d4fbcaae4ee7a0c99be7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cc767df0c743438559636c7f5f9aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6cbb56c84e40c99df665e3b4dbe803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~\\tensorflow_datasets\\fashion_mnist\\3.0.1.incompleteSDJ0MU\\fashion_mnist-train.tfrecord*...:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df916d24d8542f385e52015e080c0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c84e8b8fb74188a17abe546bf8e3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~\\tensorflow_datasets\\fashion_mnist\\3.0.1.incompleteSDJ0MU\\fashion_mnist-test.tfrecord*...:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset fashion_mnist downloaded and prepared to ~\\tensorflow_datasets\\fashion_mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "tfds.core.DatasetInfo(\n",
      "    name='fashion_mnist',\n",
      "    full_name='fashion_mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
      "    \"\"\",\n",
      "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
      "    data_path='~\\\\tensorflow_datasets\\\\fashion_mnist\\\\3.0.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=29.45 MiB,\n",
      "    dataset_size=36.42 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
      "      author    = {Han Xiao and\n",
      "                   Kashif Rasul and\n",
      "                   Roland Vollgraf},\n",
      "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
      "                   Algorithms},\n",
      "      journal   = {CoRR},\n",
      "      volume    = {abs/1708.07747},\n",
      "      year      = {2017},\n",
      "      url       = {http://arxiv.org/abs/1708.07747},\n",
      "      archivePrefix = {arXiv},\n",
      "      eprint    = {1708.07747},\n",
      "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
      "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
      "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "#print(tfds.list_builders())\n",
    "dataset, info = tfds.load('fashion_mnist', as_supervised = True, with_info = True)\n",
    "dataset_test, dataset_train = dataset['test'], dataset['train']\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_types(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "dataset_train = dataset_train.map(convert_types).shuffle(10000).batch(batch_size)\n",
    "dataset_test = dataset_test.map(convert_types).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#datagen = ImageDataGenerator()\n",
    "datagen = ImageDataGenerator(rotation_range = 10, horizontal_flip = True, zoom_range = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_net50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             multiple                  3200      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  multiple                 256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     multiple                  0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  multiple                 0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " residual_block (ResidualBlo  multiple                 75904     \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " residual_block_1 (ResidualB  multiple                 71552     \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_2 (ResidualB  multiple                 71552     \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          multiple                  131584    \n",
      "                                                                 \n",
      " residual_block_3 (ResidualB  multiple                 282368    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_4 (ResidualB  multiple                 282368    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_5 (ResidualB  multiple                 282368    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_6 (ResidualB  multiple                 282368    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          multiple                  525312    \n",
      "                                                                 \n",
      " residual_block_7 (ResidualB  multiple                 1121792   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_8 (ResidualB  multiple                 1121792   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_9 (ResidualB  multiple                 1121792   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_10 (Residual  multiple                 1121792   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_11 (Residual  multiple                 1121792   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_12 (Residual  multiple                 1121792   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          multiple                  2099200   \n",
      "                                                                 \n",
      " residual_block_13 (Residual  multiple                 4471808   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_14 (Residual  multiple                 4471808   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_15 (Residual  multiple                 4471808   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  multiple                 0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  2049000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  10010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,313,218\n",
      "Trainable params: 26,267,778\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation, MaxPool2D, GlobalAveragePooling2D, Add\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "class ResidualBlock(Model):\n",
    "    def __init__(self, channel_in = 64, channel_out = 256):\n",
    "        super().__init__()\n",
    "        \n",
    "        channel = channel_out // 4\n",
    "        \n",
    "        self.conv1 = Conv2D(channel, kernel_size = (1, 1), padding = \"same\")\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.av1 = Activation(tf.nn.relu)\n",
    "        self.conv2 = Conv2D(channel, kernel_size = (3, 3), padding = \"same\")\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.av2 = Activation(tf.nn.relu)\n",
    "        self.conv3 = Conv2D(channel_out, kernel_size = (1, 1), padding = \"same\")\n",
    "        self.bn3 = BatchNormalization()\n",
    "        self.shortcut = self._shortcut(channel_in, channel_out)\n",
    "        self.add = Add()\n",
    "        self.av3 = Activation(tf.nn.relu)\n",
    "        \n",
    "    def call(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.bn1(h)\n",
    "        h = self.av1(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.bn2(h)\n",
    "        h = self.av2(h)\n",
    "        h = self.conv3(h)\n",
    "        h = self.bn3(h)\n",
    "        shortcut = self.shortcut(x)\n",
    "        h = self.add([h, shortcut])\n",
    "        y = self.av3(h)\n",
    "        return y\n",
    "    \n",
    "    def _shortcut(self, channel_in, channel_out):\n",
    "        if channel_in == channel_out:\n",
    "            return lambda x : x\n",
    "        else:\n",
    "            return self._projection(channel_out)\n",
    "        \n",
    "    def _projection(self, channel_out):\n",
    "        return Conv2D(channel_out, kernel_size = (1, 1), padding = \"same\")\n",
    "           \n",
    "class ResNet50(Model):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        super().__init__()                \n",
    "        \n",
    "        self._layers = [\n",
    "            # conv1\n",
    "            Conv2D(64, input_shape = input_shape, kernel_size = (7, 7), strides=(2, 2), padding = \"same\"),\n",
    "            BatchNormalization(),\n",
    "            Activation(tf.nn.relu),\n",
    "            # conv2_x\n",
    "            MaxPool2D(pool_size = (3, 3), strides = (2, 2), padding = \"same\"),\n",
    "            ResidualBlock(64, 256),\n",
    "            [\n",
    "                ResidualBlock(256, 256) for _ in range(2)                \n",
    "            ],\n",
    "            # conv3_x\n",
    "            Conv2D(512, kernel_size = (1, 1), strides=(2, 2)),\n",
    "            [\n",
    "                ResidualBlock(512, 512) for _ in range(4)                \n",
    "            ],\n",
    "            # conv4_x\n",
    "            Conv2D(1024, kernel_size = (1, 1), strides=(2, 2)),\n",
    "            [\n",
    "                ResidualBlock(1024, 1024) for _ in range(6)                \n",
    "            ],\n",
    "            # conv5_x\n",
    "            Conv2D(2048, kernel_size = (1, 1), strides=(2, 2)),\n",
    "            [\n",
    "                ResidualBlock(2048, 2048) for _ in range(3)\n",
    "            ],\n",
    "            # last part\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(1000, activation = tf.nn.relu),\n",
    "            Dense(output_dim, activation = tf.nn.softmax)\n",
    "        ]\n",
    "        \n",
    "    def call(self, x):\n",
    "        for layer in self._layers:\n",
    "            if isinstance(layer, list):\n",
    "                for l in layer:\n",
    "                    x = l(x)    \n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "       \n",
    "    \n",
    "model = ResNet50((28, 28, 1), 10)\n",
    "model.build(input_shape = (None, 28, 28, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1, momentum = 0.9, decay =  0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(image)\n",
    "        loss = loss_object(label, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(label, predictions)\n",
    "        \n",
    "@tf.function\n",
    "def test_step(image, label):\n",
    "    predictions = model(image)\n",
    "    loss = loss_object(label, predictions)\n",
    "    \n",
    "    test_loss(loss)\n",
    "    test_accuracy(label, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8501887321472168, Accuracy: 67.04166412353516, Test Loss: 0.5823125839233398, Test Accuracy: 78.66999816894531, spent_time: 0.8669886906941732 min\n",
      "Epoch 2, Loss: 0.678204357624054, Accuracy: 74.02249908447266, Test Loss: 0.5028275847434998, Test Accuracy: 81.63999938964844, spent_time: 1.4578715523084005 min\n",
      "Epoch 3, Loss: 0.6002489924430847, Accuracy: 77.12388610839844, Test Loss: 0.4739997386932373, Test Accuracy: 82.56999969482422, spent_time: 2.022306478023529 min\n",
      "Epoch 4, Loss: 0.5533494353294373, Accuracy: 79.01250457763672, Test Loss: 0.4524279236793518, Test Accuracy: 83.45000457763672, spent_time: 2.522356990973155 min\n",
      "Epoch 5, Loss: 0.520905077457428, Accuracy: 80.28333282470703, Test Loss: 0.4402647316455841, Test Accuracy: 83.91400146484375, spent_time: 3.0381226936976113 min\n",
      "Epoch 6, Loss: 0.4960748255252838, Accuracy: 81.2508316040039, Test Loss: 0.4228503704071045, Test Accuracy: 84.63333129882812, spent_time: 3.5438119093577067 min\n",
      "Epoch 7, Loss: 0.47583144903182983, Accuracy: 82.03881072998047, Test Loss: 0.4099331796169281, Test Accuracy: 85.1385726928711, spent_time: 4.066916938622793 min\n",
      "Epoch 8, Loss: 0.4598933756351471, Accuracy: 82.64749908447266, Test Loss: 0.4008658826351166, Test Accuracy: 85.54750061035156, spent_time: 4.585361917813619 min\n",
      "Epoch 9, Loss: 0.4456733763217926, Accuracy: 83.20055389404297, Test Loss: 0.39233604073524475, Test Accuracy: 85.87333679199219, spent_time: 5.125349549452464 min\n",
      "Epoch 10, Loss: 0.43339458107948303, Accuracy: 83.67233276367188, Test Loss: 0.38399824500083923, Test Accuracy: 86.17200469970703, spent_time: 5.666275378068288 min\n",
      "Epoch 11, Loss: 0.42286252975463867, Accuracy: 84.07393646240234, Test Loss: 0.37786510586738586, Test Accuracy: 86.39909362792969, spent_time: 6.212287449836731 min\n",
      "Epoch 12, Loss: 0.41374748945236206, Accuracy: 84.42013549804688, Test Loss: 0.3731788694858551, Test Accuracy: 86.58583068847656, spent_time: 6.731276305516561 min\n",
      "Epoch 13, Loss: 0.4054327607154846, Accuracy: 84.73846435546875, Test Loss: 0.3680585026741028, Test Accuracy: 86.78384399414062, spent_time: 7.251072406768799 min\n",
      "Epoch 14, Loss: 0.3978724777698517, Accuracy: 85.03607177734375, Test Loss: 0.3635503351688385, Test Accuracy: 86.96214294433594, spent_time: 7.771388161182403 min\n",
      "Epoch 15, Loss: 0.3906908631324768, Accuracy: 85.31121826171875, Test Loss: 0.35868802666664124, Test Accuracy: 87.11199951171875, spent_time: 8.287430703639984 min\n",
      "Epoch 16, Loss: 0.38424623012542725, Accuracy: 85.5503158569336, Test Loss: 0.3540031909942627, Test Accuracy: 87.27750396728516, spent_time: 8.783062394460043 min\n",
      "Epoch 17, Loss: 0.37847375869750977, Accuracy: 85.7752914428711, Test Loss: 0.3505627512931824, Test Accuracy: 87.4064712524414, spent_time: 9.292545366287232 min\n",
      "Epoch 18, Loss: 0.37322095036506653, Accuracy: 85.97999572753906, Test Loss: 0.34739336371421814, Test Accuracy: 87.52999877929688, spent_time: 9.793448189894358 min\n",
      "Epoch 19, Loss: 0.3683042526245117, Accuracy: 86.17315673828125, Test Loss: 0.3443445861339569, Test Accuracy: 87.66578674316406, spent_time: 10.302911273638408 min\n",
      "Epoch 20, Loss: 0.3635099530220032, Accuracy: 86.35758209228516, Test Loss: 0.3420439660549164, Test Accuracy: 87.77649688720703, spent_time: 10.826095839341482 min\n",
      "Epoch 21, Loss: 0.35904282331466675, Accuracy: 86.52397155761719, Test Loss: 0.3393249213695526, Test Accuracy: 87.89714813232422, spent_time: 11.340986367066701 min\n",
      "Epoch 22, Loss: 0.3548063039779663, Accuracy: 86.68696594238281, Test Loss: 0.33773207664489746, Test Accuracy: 87.95863342285156, spent_time: 11.82201782464981 min\n",
      "Epoch 23, Loss: 0.35080838203430176, Accuracy: 86.83638000488281, Test Loss: 0.33476415276527405, Test Accuracy: 88.06260681152344, spent_time: 12.30598071416219 min\n",
      "Epoch 24, Loss: 0.34689846634864807, Accuracy: 86.98527526855469, Test Loss: 0.33233386278152466, Test Accuracy: 88.15167236328125, spent_time: 12.81218108733495 min\n",
      "Epoch 25, Loss: 0.3433895707130432, Accuracy: 87.1195297241211, Test Loss: 0.3300134837627411, Test Accuracy: 88.23760223388672, spent_time: 13.324524637063345 min\n",
      "Epoch 26, Loss: 0.33999666571617126, Accuracy: 87.24820709228516, Test Loss: 0.3280662000179291, Test Accuracy: 88.30038452148438, spent_time: 13.80227157274882 min\n",
      "Epoch 27, Loss: 0.3366977870464325, Accuracy: 87.36734008789062, Test Loss: 0.32603153586387634, Test Accuracy: 88.3677749633789, spent_time: 14.272192366917928 min\n",
      "Epoch 28, Loss: 0.3334742784500122, Accuracy: 87.48863220214844, Test Loss: 0.32492294907569885, Test Accuracy: 88.43463897705078, spent_time: 14.739874815940857 min\n",
      "Epoch 29, Loss: 0.3306131064891815, Accuracy: 87.5960922241211, Test Loss: 0.32343170046806335, Test Accuracy: 88.49930572509766, spent_time: 15.218022855122884 min\n",
      "Epoch 30, Loss: 0.3278518617153168, Accuracy: 87.7044448852539, Test Loss: 0.321483314037323, Test Accuracy: 88.56400299072266, spent_time: 15.696846083799999 min\n",
      "Epoch 31, Loss: 0.3250320255756378, Accuracy: 87.81075286865234, Test Loss: 0.3206941783428192, Test Accuracy: 88.62161254882812, spent_time: 16.18012719154358 min\n",
      "Epoch 32, Loss: 0.3224758207798004, Accuracy: 87.90703582763672, Test Loss: 0.31901657581329346, Test Accuracy: 88.6890640258789, spent_time: 16.652313709259033 min\n",
      "Epoch 33, Loss: 0.3197963237762451, Accuracy: 88.00626373291016, Test Loss: 0.3173379600048065, Test Accuracy: 88.74666595458984, spent_time: 17.12580557266871 min\n",
      "Epoch 34, Loss: 0.3172886371612549, Accuracy: 88.09789276123047, Test Loss: 0.31608885526657104, Test Accuracy: 88.79087829589844, spent_time: 17.635096991062163 min\n",
      "Epoch 35, Loss: 0.3155067265033722, Accuracy: 88.16924285888672, Test Loss: 0.3145427703857422, Test Accuracy: 88.84742736816406, spent_time: 18.114990043640137 min\n",
      "Epoch 36, Loss: 0.3130947947502136, Accuracy: 88.25629425048828, Test Loss: 0.31298133730888367, Test Accuracy: 88.91722106933594, spent_time: 18.580462523301442 min\n",
      "Epoch 37, Loss: 0.3108923137187958, Accuracy: 88.33712005615234, Test Loss: 0.31194350123405457, Test Accuracy: 88.95756530761719, spent_time: 19.046869309743247 min\n",
      "Epoch 38, Loss: 0.3086937963962555, Accuracy: 88.4192123413086, Test Loss: 0.3107854723930359, Test Accuracy: 88.98973083496094, spent_time: 19.515398450692494 min\n",
      "Epoch 39, Loss: 0.3065372109413147, Accuracy: 88.4974365234375, Test Loss: 0.309801310300827, Test Accuracy: 89.02896881103516, spent_time: 19.989103492101034 min\n",
      "Epoch 40, Loss: 0.3045301139354706, Accuracy: 88.57041931152344, Test Loss: 0.3086421489715576, Test Accuracy: 89.0877456665039, spent_time: 20.464041252930958 min\n",
      "Epoch 41, Loss: 0.3025488555431366, Accuracy: 88.64617919921875, Test Loss: 0.3079271912574768, Test Accuracy: 89.11316680908203, spent_time: 20.958010947704317 min\n",
      "Epoch 42, Loss: 0.30070146918296814, Accuracy: 88.71432495117188, Test Loss: 0.306896448135376, Test Accuracy: 89.15071105957031, spent_time: 21.467223195234933 min\n",
      "Epoch 43, Loss: 0.29881027340888977, Accuracy: 88.7846908569336, Test Loss: 0.30551478266716003, Test Accuracy: 89.19953918457031, spent_time: 22.188780649503073 min\n",
      "Epoch 44, Loss: 0.29694145917892456, Accuracy: 88.85352325439453, Test Loss: 0.3045189082622528, Test Accuracy: 89.2404556274414, spent_time: 22.87325576146444 min\n",
      "Epoch 45, Loss: 0.2951302230358124, Accuracy: 88.92229461669922, Test Loss: 0.3034316897392273, Test Accuracy: 89.28888702392578, spent_time: 23.57157466808955 min\n",
      "Epoch 46, Loss: 0.2933709919452667, Accuracy: 88.98699188232422, Test Loss: 0.3024579882621765, Test Accuracy: 89.32826232910156, spent_time: 24.266429976622263 min\n",
      "Epoch 47, Loss: 0.29162371158599854, Accuracy: 89.05138397216797, Test Loss: 0.30187004804611206, Test Accuracy: 89.36084747314453, spent_time: 24.91464693546295 min\n",
      "Epoch 48, Loss: 0.2899535298347473, Accuracy: 89.11347198486328, Test Loss: 0.30124199390411377, Test Accuracy: 89.38916778564453, spent_time: 25.607295560836793 min\n",
      "Epoch 49, Loss: 0.28858140110969543, Accuracy: 89.16381072998047, Test Loss: 0.3004430830478668, Test Accuracy: 89.41897583007812, spent_time: 26.127161761124928 min\n",
      "Epoch 50, Loss: 0.2870135009288788, Accuracy: 89.22173309326172, Test Loss: 0.2994511127471924, Test Accuracy: 89.45359802246094, spent_time: 26.636358070373536 min\n",
      "Epoch 51, Loss: 0.2854582369327545, Accuracy: 89.27911376953125, Test Loss: 0.29877814650535583, Test Accuracy: 89.48529052734375, spent_time: 27.144267106056212 min\n",
      "Epoch 52, Loss: 0.2839236259460449, Accuracy: 89.33625030517578, Test Loss: 0.2982631027698517, Test Accuracy: 89.50596618652344, spent_time: 27.629964073499043 min\n",
      "Epoch 53, Loss: 0.28253573179244995, Accuracy: 89.3863525390625, Test Loss: 0.29780343174934387, Test Accuracy: 89.51962280273438, spent_time: 28.113980968793232 min\n",
      "Epoch 54, Loss: 0.2810334861278534, Accuracy: 89.43932342529297, Test Loss: 0.29677483439445496, Test Accuracy: 89.56000518798828, spent_time: 28.638690940539043 min\n",
      "Epoch 55, Loss: 0.2796470820903778, Accuracy: 89.49093627929688, Test Loss: 0.2959554195404053, Test Accuracy: 89.5950927734375, spent_time: 29.153887649377186 min\n",
      "Epoch 56, Loss: 0.2782302796840668, Accuracy: 89.54532623291016, Test Loss: 0.2951984703540802, Test Accuracy: 89.63088989257812, spent_time: 29.68015675544739 min\n",
      "Epoch 57, Loss: 0.27684521675109863, Accuracy: 89.59654998779297, Test Loss: 0.2945403754711151, Test Accuracy: 89.65771484375, spent_time: 30.184559778372446 min\n",
      "Epoch 58, Loss: 0.27556297183036804, Accuracy: 89.6473617553711, Test Loss: 0.29376327991485596, Test Accuracy: 89.68706512451172, spent_time: 30.696248813470206 min\n",
      "Epoch 59, Loss: 0.27423763275146484, Accuracy: 89.6956787109375, Test Loss: 0.29312863945961, Test Accuracy: 89.72101593017578, spent_time: 31.23865796327591 min\n",
      "Epoch 60, Loss: 0.2729783058166504, Accuracy: 89.74250030517578, Test Loss: 0.29219263792037964, Test Accuracy: 89.7586669921875, spent_time: 31.74284042517344 min\n",
      "Epoch 61, Loss: 0.27170413732528687, Accuracy: 89.79005432128906, Test Loss: 0.2915107011795044, Test Accuracy: 89.784423828125, spent_time: 32.2689613699913 min\n",
      "Epoch 62, Loss: 0.27044808864593506, Accuracy: 89.83674621582031, Test Loss: 0.29086482524871826, Test Accuracy: 89.80790710449219, spent_time: 32.80724322398503 min\n",
      "Epoch 63, Loss: 0.26923948526382446, Accuracy: 89.88121795654297, Test Loss: 0.29022282361984253, Test Accuracy: 89.83492279052734, spent_time: 33.315556557973224 min\n",
      "Epoch 64, Loss: 0.2680369019508362, Accuracy: 89.92674255371094, Test Loss: 0.2897360324859619, Test Accuracy: 89.8565673828125, spent_time: 33.818594622612 min\n",
      "Epoch 65, Loss: 0.26684823632240295, Accuracy: 89.97054290771484, Test Loss: 0.28918948769569397, Test Accuracy: 89.8852310180664, spent_time: 34.30799372196198 min\n",
      "Epoch 66, Loss: 0.26627659797668457, Accuracy: 89.99327850341797, Test Loss: 0.28893065452575684, Test Accuracy: 89.89348602294922, spent_time: 34.81177852153778 min\n",
      "Epoch 67, Loss: 0.26538440585136414, Accuracy: 90.02644348144531, Test Loss: 0.2885572016239166, Test Accuracy: 89.91253662109375, spent_time: 35.33116125663121 min\n",
      "Epoch 68, Loss: 0.2642664909362793, Accuracy: 90.06732940673828, Test Loss: 0.28795817494392395, Test Accuracy: 89.9366226196289, spent_time: 35.82049961487452 min\n",
      "Epoch 69, Loss: 0.2631635367870331, Accuracy: 90.10828399658203, Test Loss: 0.28734511137008667, Test Accuracy: 89.96217346191406, spent_time: 36.325621076424916 min\n",
      "Epoch 70, Loss: 0.2620365619659424, Accuracy: 90.14909362792969, Test Loss: 0.28701525926589966, Test Accuracy: 89.9874267578125, spent_time: 36.81094475189845 min\n",
      "Epoch 71, Loss: 0.26092448830604553, Accuracy: 90.18983459472656, Test Loss: 0.28662508726119995, Test Accuracy: 90.01239776611328, spent_time: 37.290116182963054 min\n",
      "Epoch 72, Loss: 0.25984326004981995, Accuracy: 90.23069763183594, Test Loss: 0.28634482622146606, Test Accuracy: 90.03250122070312, spent_time: 37.78773729403814 min\n",
      "Epoch 73, Loss: 0.2588253319263458, Accuracy: 90.2675552368164, Test Loss: 0.28603336215019226, Test Accuracy: 90.0517807006836, spent_time: 38.278723573684694 min\n",
      "Epoch 74, Loss: 0.2578190565109253, Accuracy: 90.3055191040039, Test Loss: 0.28566646575927734, Test Accuracy: 90.07567596435547, spent_time: 38.77383775313695 min\n",
      "Epoch 75, Loss: 0.25681617856025696, Accuracy: 90.34126281738281, Test Loss: 0.28542816638946533, Test Accuracy: 90.09573364257812, spent_time: 39.25493590831756 min\n",
      "Epoch 76, Loss: 0.25592678785324097, Accuracy: 90.37406158447266, Test Loss: 0.28537362813949585, Test Accuracy: 90.09947204589844, spent_time: 39.750633629163104 min\n",
      "Epoch 77, Loss: 0.2560367286205292, Accuracy: 90.37774658203125, Test Loss: 0.2851351499557495, Test Accuracy: 90.11038970947266, spent_time: 40.23943581183752 min\n",
      "Epoch 78, Loss: 0.25533363223075867, Accuracy: 90.40352630615234, Test Loss: 0.2846904993057251, Test Accuracy: 90.12538146972656, spent_time: 40.72661796808243 min\n",
      "Epoch 79, Loss: 0.25445225834846497, Accuracy: 90.43436431884766, Test Loss: 0.2840797007083893, Test Accuracy: 90.1443099975586, spent_time: 41.225143488248186 min\n",
      "Epoch 80, Loss: 0.25352126359939575, Accuracy: 90.4695816040039, Test Loss: 0.28368300199508667, Test Accuracy: 90.16337585449219, spent_time: 41.70403198401133 min\n",
      "Epoch 81, Loss: 0.25255635380744934, Accuracy: 90.50450134277344, Test Loss: 0.2834123969078064, Test Accuracy: 90.17951202392578, spent_time: 42.1703134338061 min\n",
      "Epoch 82, Loss: 0.2516009509563446, Accuracy: 90.53882598876953, Test Loss: 0.2831481695175171, Test Accuracy: 90.19487762451172, spent_time: 42.63555000623067 min\n",
      "Epoch 83, Loss: 0.2506643533706665, Accuracy: 90.57343292236328, Test Loss: 0.2828211188316345, Test Accuracy: 90.20987701416016, spent_time: 43.10360181728999 min\n",
      "Epoch 84, Loss: 0.2497631460428238, Accuracy: 90.60690307617188, Test Loss: 0.2825290560722351, Test Accuracy: 90.22297668457031, spent_time: 43.57007255554199 min\n",
      "Epoch 85, Loss: 0.24884019792079926, Accuracy: 90.64125061035156, Test Loss: 0.282145619392395, Test Accuracy: 90.2428207397461, spent_time: 44.035652577877045 min\n",
      "Epoch 86, Loss: 0.24793535470962524, Accuracy: 90.67375946044922, Test Loss: 0.2819279432296753, Test Accuracy: 90.25743865966797, spent_time: 44.5028245528539 min\n",
      "Epoch 87, Loss: 0.24702873826026917, Accuracy: 90.70735931396484, Test Loss: 0.28157681226730347, Test Accuracy: 90.27172088623047, spent_time: 44.968431401252744 min\n",
      "Epoch 88, Loss: 0.24615854024887085, Accuracy: 90.73958587646484, Test Loss: 0.28127995133399963, Test Accuracy: 90.29010772705078, spent_time: 45.43504988749822 min\n",
      "Epoch 89, Loss: 0.24600110948085785, Accuracy: 90.74915313720703, Test Loss: 0.2810463309288025, Test Accuracy: 90.30168914794922, spent_time: 45.906768155097964 min\n",
      "Epoch 90, Loss: 0.2453421801328659, Accuracy: 90.77297973632812, Test Loss: 0.28070491552352905, Test Accuracy: 90.31722259521484, spent_time: 46.37509580850601 min\n",
      "Epoch 91, Loss: 0.24458202719688416, Accuracy: 90.80076599121094, Test Loss: 0.28037190437316895, Test Accuracy: 90.33142852783203, spent_time: 46.840209142367044 min\n",
      "Epoch 92, Loss: 0.24372519552707672, Accuracy: 90.83182525634766, Test Loss: 0.2801657021045685, Test Accuracy: 90.34272003173828, spent_time: 47.30403396685918 min\n",
      "Epoch 93, Loss: 0.2428683042526245, Accuracy: 90.86365509033203, Test Loss: 0.2799359858036041, Test Accuracy: 90.35839080810547, spent_time: 47.77018671830495 min\n",
      "Epoch 94, Loss: 0.24201534688472748, Accuracy: 90.8947525024414, Test Loss: 0.27973324060440063, Test Accuracy: 90.37159729003906, spent_time: 48.23648418982824 min\n",
      "Epoch 95, Loss: 0.24118229746818542, Accuracy: 90.92508697509766, Test Loss: 0.2795129716396332, Test Accuracy: 90.38926696777344, spent_time: 48.70248452822367 min\n",
      "Epoch 96, Loss: 0.24035607278347015, Accuracy: 90.95591735839844, Test Loss: 0.2794554531574249, Test Accuracy: 90.40479278564453, spent_time: 49.16591289440791 min\n",
      "Epoch 97, Loss: 0.24000054597854614, Accuracy: 90.96945190429688, Test Loss: 0.2794658839702606, Test Accuracy: 90.40567016601562, spent_time: 49.63138945102692 min\n",
      "Epoch 98, Loss: 0.239350825548172, Accuracy: 90.99365234375, Test Loss: 0.2793163061141968, Test Accuracy: 90.41500091552734, spent_time: 50.095856694380444 min\n",
      "Epoch 99, Loss: 0.23861248791217804, Accuracy: 91.02141571044922, Test Loss: 0.27906525135040283, Test Accuracy: 90.42980194091797, spent_time: 50.56237442890803 min\n",
      "Epoch 100, Loss: 0.23787271976470947, Accuracy: 91.04814910888672, Test Loss: 0.2789281904697418, Test Accuracy: 90.43980407714844, spent_time: 51.02898347377777 min\n",
      "Epoch 101, Loss: 0.23711863160133362, Accuracy: 91.07637023925781, Test Loss: 0.278779000043869, Test Accuracy: 90.44891357421875, spent_time: 51.49410740534464 min\n",
      "Epoch 102, Loss: 0.2363719940185547, Accuracy: 91.10443115234375, Test Loss: 0.2788057327270508, Test Accuracy: 90.45764923095703, spent_time: 51.95645330349604 min\n",
      "Epoch 103, Loss: 0.23566661775112152, Accuracy: 91.13098907470703, Test Loss: 0.2786480188369751, Test Accuracy: 90.46670532226562, spent_time: 52.42387475967407 min\n",
      "Epoch 104, Loss: 0.2349352240562439, Accuracy: 91.15890502929688, Test Loss: 0.27883651852607727, Test Accuracy: 90.47547912597656, spent_time: 52.88847150802612 min\n",
      "Epoch 105, Loss: 0.23424631357192993, Accuracy: 91.18441009521484, Test Loss: 0.2786277234554291, Test Accuracy: 90.48694610595703, spent_time: 53.353650816281636 min\n",
      "Epoch 106, Loss: 0.23358508944511414, Accuracy: 91.20941925048828, Test Loss: 0.27859625220298767, Test Accuracy: 90.49613189697266, spent_time: 53.81941788593928 min\n",
      "Epoch 107, Loss: 0.2328929603099823, Accuracy: 91.23500061035156, Test Loss: 0.27856937050819397, Test Accuracy: 90.50495910644531, spent_time: 54.2838933467865 min\n",
      "Epoch 108, Loss: 0.23217929899692535, Accuracy: 91.26116180419922, Test Loss: 0.27890971302986145, Test Accuracy: 90.51370239257812, spent_time: 54.74943811098735 min\n",
      "Epoch 109, Loss: 0.2315371036529541, Accuracy: 91.28598022460938, Test Loss: 0.2790152430534363, Test Accuracy: 90.52375793457031, spent_time: 55.21716341177623 min\n",
      "Epoch 110, Loss: 0.23116718232631683, Accuracy: 91.3012466430664, Test Loss: 0.27953141927719116, Test Accuracy: 90.50545501708984, spent_time: 55.68277462323507 min\n",
      "Epoch 111, Loss: 0.23084749281406403, Accuracy: 91.31294250488281, Test Loss: 0.2794159948825836, Test Accuracy: 90.51729583740234, spent_time: 56.152572568257646 min\n",
      "Epoch 112, Loss: 0.2302200049161911, Accuracy: 91.33625030517578, Test Loss: 0.2793751657009125, Test Accuracy: 90.52910614013672, spent_time: 56.65877394676208 min\n",
      "Epoch 113, Loss: 0.22969435155391693, Accuracy: 91.35582733154297, Test Loss: 0.2792549431324005, Test Accuracy: 90.53407287597656, spent_time: 57.18351562817892 min\n",
      "Epoch 114, Loss: 0.22902990877628326, Accuracy: 91.37989807128906, Test Loss: 0.27916014194488525, Test Accuracy: 90.54447174072266, spent_time: 57.6736739397049 min\n",
      "Epoch 115, Loss: 0.22832465171813965, Accuracy: 91.4054946899414, Test Loss: 0.2789827883243561, Test Accuracy: 90.55756378173828, spent_time: 58.15442480246226 min\n",
      "Epoch 116, Loss: 0.22762185335159302, Accuracy: 91.43102264404297, Test Loss: 0.27893394231796265, Test Accuracy: 90.56809997558594, spent_time: 58.630249420801796 min\n",
      "Epoch 117, Loss: 0.22698789834976196, Accuracy: 91.45427703857422, Test Loss: 0.27893730998039246, Test Accuracy: 90.57418823242188, spent_time: 59.120126418272655 min\n",
      "Epoch 118, Loss: 0.2263767272233963, Accuracy: 91.47702026367188, Test Loss: 0.27878352999687195, Test Accuracy: 90.58499908447266, spent_time: 59.63869466384252 min\n",
      "Epoch 119, Loss: 0.2257104516029358, Accuracy: 91.50215911865234, Test Loss: 0.27882012724876404, Test Accuracy: 90.59159851074219, spent_time: 60.1435997525851 min\n",
      "Epoch 120, Loss: 0.2250485122203827, Accuracy: 91.527099609375, Test Loss: 0.2788448929786682, Test Accuracy: 90.5995864868164, spent_time: 60.63578068017959 min\n",
      "Epoch 121, Loss: 0.22442907094955444, Accuracy: 91.55043029785156, Test Loss: 0.27895480394363403, Test Accuracy: 90.60694122314453, spent_time: 61.12548992236455 min\n",
      "Epoch 122, Loss: 0.22383932769298553, Accuracy: 91.57217407226562, Test Loss: 0.2789037227630615, Test Accuracy: 90.61385345458984, spent_time: 61.613433531920116 min\n",
      "Epoch 123, Loss: 0.22322537004947662, Accuracy: 91.59551239013672, Test Loss: 0.2790764570236206, Test Accuracy: 90.61780548095703, spent_time: 62.10425442457199 min\n",
      "Epoch 124, Loss: 0.2226216197013855, Accuracy: 91.61811828613281, Test Loss: 0.27906307578086853, Test Accuracy: 90.62250518798828, spent_time: 62.602940428256986 min\n",
      "Epoch 125, Loss: 0.2220180630683899, Accuracy: 91.63988494873047, Test Loss: 0.27893832325935364, Test Accuracy: 90.6308822631836, spent_time: 63.09297324419022 min\n",
      "Epoch 126, Loss: 0.22141268849372864, Accuracy: 91.66263580322266, Test Loss: 0.27890703082084656, Test Accuracy: 90.63976287841797, spent_time: 63.58478623231252 min\n",
      "Epoch 127, Loss: 0.2208167016506195, Accuracy: 91.68488311767578, Test Loss: 0.27886950969696045, Test Accuracy: 90.64834594726562, spent_time: 64.0864514986674 min\n",
      "Epoch 128, Loss: 0.22022123634815216, Accuracy: 91.70700073242188, Test Loss: 0.27894261479377747, Test Accuracy: 90.65547180175781, spent_time: 64.56245110034942 min\n",
      "Epoch 129, Loss: 0.2196388989686966, Accuracy: 91.7286148071289, Test Loss: 0.27894073724746704, Test Accuracy: 90.66278839111328, spent_time: 65.0380440711975 min\n",
      "Epoch 130, Loss: 0.21904899179935455, Accuracy: 91.75003814697266, Test Loss: 0.2789200246334076, Test Accuracy: 90.67169189453125, spent_time: 65.51145662069321 min\n",
      "Epoch 131, Loss: 0.21847157180309296, Accuracy: 91.77163696289062, Test Loss: 0.27888938784599304, Test Accuracy: 90.67862701416016, spent_time: 65.98386912345886 min\n",
      "Epoch 132, Loss: 0.21790580451488495, Accuracy: 91.7923355102539, Test Loss: 0.2789619565010071, Test Accuracy: 90.68302917480469, spent_time: 66.45326147874196 min\n",
      "Epoch 133, Loss: 0.21735984086990356, Accuracy: 91.81253051757812, Test Loss: 0.27881133556365967, Test Accuracy: 90.69180297851562, spent_time: 66.92391347885132 min\n",
      "Epoch 134, Loss: 0.2168091982603073, Accuracy: 91.83196258544922, Test Loss: 0.2788609266281128, Test Accuracy: 90.6962661743164, spent_time: 67.39085570176442 min\n",
      "Epoch 135, Loss: 0.21624386310577393, Accuracy: 91.85310363769531, Test Loss: 0.2790263593196869, Test Accuracy: 90.70378112792969, spent_time: 67.85741798480352 min\n",
      "Epoch 136, Loss: 0.2156936675310135, Accuracy: 91.87445068359375, Test Loss: 0.2789120674133301, Test Accuracy: 90.71095275878906, spent_time: 68.32288030783336 min\n",
      "Epoch 137, Loss: 0.21511903405189514, Accuracy: 91.89598846435547, Test Loss: 0.279026061296463, Test Accuracy: 90.71656799316406, spent_time: 68.78811401526133 min\n",
      "Epoch 138, Loss: 0.21457239985466003, Accuracy: 91.9161605834961, Test Loss: 0.2790522277355194, Test Accuracy: 90.72137451171875, spent_time: 69.2530916372935 min\n",
      "Epoch 139, Loss: 0.2140258252620697, Accuracy: 91.937744140625, Test Loss: 0.27906355261802673, Test Accuracy: 90.72913360595703, spent_time: 69.719602560997 min\n",
      "Epoch 140, Loss: 0.21343757212162018, Accuracy: 91.96033477783203, Test Loss: 0.2792958617210388, Test Accuracy: 90.73342895507812, spent_time: 70.18794128100078 min\n",
      "Epoch 141, Loss: 0.21296708285808563, Accuracy: 91.97898864746094, Test Loss: 0.27945393323898315, Test Accuracy: 90.73283386230469, spent_time: 70.65321555534999 min\n",
      "Epoch 142, Loss: 0.21243424713611603, Accuracy: 91.99829864501953, Test Loss: 0.279585599899292, Test Accuracy: 90.74028015136719, spent_time: 71.12277162075043 min\n",
      "Epoch 143, Loss: 0.21187300980091095, Accuracy: 92.01875305175781, Test Loss: 0.27976271510124207, Test Accuracy: 90.74195861816406, spent_time: 71.61021564801534 min\n",
      "Epoch 144, Loss: 0.21169455349445343, Accuracy: 92.0258560180664, Test Loss: 0.2798711359500885, Test Accuracy: 90.74749755859375, spent_time: 72.10074288050333 min\n",
      "Epoch 145, Loss: 0.21122683584690094, Accuracy: 92.04334259033203, Test Loss: 0.2799549698829651, Test Accuracy: 90.74820709228516, spent_time: 72.58121300538382 min\n",
      "Epoch 146, Loss: 0.21069806814193726, Accuracy: 92.062744140625, Test Loss: 0.27994194626808167, Test Accuracy: 90.7535629272461, spent_time: 73.06393216848373 min\n",
      "Epoch 147, Loss: 0.21014605462551117, Accuracy: 92.08335876464844, Test Loss: 0.27994826436042786, Test Accuracy: 90.75666809082031, spent_time: 73.55404544671377 min\n",
      "Epoch 148, Loss: 0.2095784693956375, Accuracy: 92.10482788085938, Test Loss: 0.28005704283714294, Test Accuracy: 90.76202392578125, spent_time: 74.04617532491685 min\n",
      "Epoch 149, Loss: 0.20904697477817535, Accuracy: 92.12434387207031, Test Loss: 0.280050665140152, Test Accuracy: 90.76972961425781, spent_time: 74.53462785482407 min\n",
      "Epoch 150, Loss: 0.20850896835327148, Accuracy: 92.1441421508789, Test Loss: 0.2799997329711914, Test Accuracy: 90.77766418457031, spent_time: 75.02524557511012 min\n",
      "Epoch 151, Loss: 0.2080012708902359, Accuracy: 92.16320037841797, Test Loss: 0.2801356315612793, Test Accuracy: 90.78211975097656, spent_time: 75.5063445965449 min\n",
      "Epoch 152, Loss: 0.20972873270511627, Accuracy: 92.1366958618164, Test Loss: 0.28050968050956726, Test Accuracy: 90.76348876953125, spent_time: 76.00101468165715 min\n",
      "Epoch 153, Loss: 0.21035638451576233, Accuracy: 92.11266326904297, Test Loss: 0.28070884943008423, Test Accuracy: 90.7509765625, spent_time: 76.49864577849706 min\n",
      "Epoch 154, Loss: 0.21076419949531555, Accuracy: 92.0966796875, Test Loss: 0.2807683050632477, Test Accuracy: 90.74415588378906, spent_time: 76.98673173586528 min\n",
      "Epoch 155, Loss: 0.21101641654968262, Accuracy: 92.08644104003906, Test Loss: 0.2808188498020172, Test Accuracy: 90.7416763305664, spent_time: 77.47061211665472 min\n",
      "Epoch 156, Loss: 0.2111593633890152, Accuracy: 92.080322265625, Test Loss: 0.2808336317539215, Test Accuracy: 90.73877716064453, spent_time: 77.95590866804123 min\n",
      "Epoch 157, Loss: 0.21119807660579681, Accuracy: 92.07769775390625, Test Loss: 0.280839741230011, Test Accuracy: 90.73738861083984, spent_time: 78.4450180331866 min\n",
      "Epoch 158, Loss: 0.2111736536026001, Accuracy: 92.07754516601562, Test Loss: 0.28080180287361145, Test Accuracy: 90.73512268066406, spent_time: 78.9299240787824 min\n",
      "Epoch 159, Loss: 0.2110777646303177, Accuracy: 92.07984161376953, Test Loss: 0.2807960510253906, Test Accuracy: 90.73408508300781, spent_time: 79.41944304307302 min\n",
      "Epoch 160, Loss: 0.21092355251312256, Accuracy: 92.08451080322266, Test Loss: 0.2807132303714752, Test Accuracy: 90.734375, spent_time: 79.90349498589833 min\n",
      "Epoch 161, Loss: 0.21070753037929535, Accuracy: 92.09183502197266, Test Loss: 0.2806991934776306, Test Accuracy: 90.73316955566406, spent_time: 80.39602362712225 min\n",
      "Epoch 162, Loss: 0.2104470282793045, Accuracy: 92.10081481933594, Test Loss: 0.2806936204433441, Test Accuracy: 90.73296356201172, spent_time: 80.89099617004395 min\n",
      "Epoch 163, Loss: 0.2101222276687622, Accuracy: 92.11187744140625, Test Loss: 0.2807249426841736, Test Accuracy: 90.7336196899414, spent_time: 81.37598697344463 min\n",
      "Epoch 164, Loss: 0.209745854139328, Accuracy: 92.12557983398438, Test Loss: 0.2807673215866089, Test Accuracy: 90.73773956298828, spent_time: 81.87251442670822 min\n",
      "Epoch 165, Loss: 0.2093132585287094, Accuracy: 92.1411361694336, Test Loss: 0.28086966276168823, Test Accuracy: 90.741455078125, spent_time: 82.35666744709015 min\n",
      "Epoch 166, Loss: 0.20887477695941925, Accuracy: 92.15707397460938, Test Loss: 0.2809327244758606, Test Accuracy: 90.74457550048828, spent_time: 82.84822002649307 min\n",
      "Epoch 167, Loss: 0.20841002464294434, Accuracy: 92.174072265625, Test Loss: 0.28125885128974915, Test Accuracy: 90.74658966064453, spent_time: 83.34403030077617 min\n",
      "Epoch 168, Loss: 0.2079390436410904, Accuracy: 92.19205474853516, Test Loss: 0.28138357400894165, Test Accuracy: 90.75065612792969, spent_time: 83.82474075158437 min\n",
      "Epoch 169, Loss: 0.20744183659553528, Accuracy: 92.21031951904297, Test Loss: 0.28157904744148254, Test Accuracy: 90.75562286376953, spent_time: 84.32686847050985 min\n",
      "Epoch 170, Loss: 0.20694196224212646, Accuracy: 92.22892761230469, Test Loss: 0.2817688286304474, Test Accuracy: 90.76000213623047, spent_time: 84.80301573673884 min\n",
      "Epoch 171, Loss: 0.20645003020763397, Accuracy: 92.24685668945312, Test Loss: 0.2819208800792694, Test Accuracy: 90.76432800292969, spent_time: 85.27667527596155 min\n",
      "Epoch 172, Loss: 0.2059573382139206, Accuracy: 92.26507568359375, Test Loss: 0.2820802628993988, Test Accuracy: 90.76947784423828, spent_time: 85.74607129494349 min\n",
      "Epoch 173, Loss: 0.20545446872711182, Accuracy: 92.28366088867188, Test Loss: 0.28234127163887024, Test Accuracy: 90.77144622802734, spent_time: 86.22609920501709 min\n",
      "Epoch 174, Loss: 0.20498821139335632, Accuracy: 92.30169677734375, Test Loss: 0.28247934579849243, Test Accuracy: 90.77511596679688, spent_time: 86.72816115617752 min\n",
      "Epoch 175, Loss: 0.2045026272535324, Accuracy: 92.31915283203125, Test Loss: 0.28269073367118835, Test Accuracy: 90.77925872802734, spent_time: 87.22407898902892 min\n",
      "Epoch 176, Loss: 0.20481006801128387, Accuracy: 92.30900573730469, Test Loss: 0.28277578949928284, Test Accuracy: 90.7760238647461, spent_time: 87.72174189090728 min\n",
      "Epoch 177, Loss: 0.20467664301395416, Accuracy: 92.31301879882812, Test Loss: 0.282637357711792, Test Accuracy: 90.78022766113281, spent_time: 88.2297114332517 min\n",
      "Epoch 178, Loss: 0.20432215929031372, Accuracy: 92.32571411132812, Test Loss: 0.28276386857032776, Test Accuracy: 90.78359985351562, spent_time: 88.74032096862793 min\n",
      "Epoch 179, Loss: 0.20390728116035461, Accuracy: 92.3408203125, Test Loss: 0.28293377161026, Test Accuracy: 90.78714752197266, spent_time: 89.23284811576208 min\n",
      "Epoch 180, Loss: 0.20345762372016907, Accuracy: 92.35745239257812, Test Loss: 0.28311997652053833, Test Accuracy: 90.7912826538086, spent_time: 89.73440234263738 min\n",
      "Epoch 181, Loss: 0.20299914479255676, Accuracy: 92.37410736083984, Test Loss: 0.2832472324371338, Test Accuracy: 90.79552459716797, spent_time: 90.23000610272089 min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epoch = 400\n",
    "start_time = time.time()\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epoch):    \n",
    "    for image, label in dataset_train:\n",
    "        for _image, _label in datagen.flow(image, label, batch_size = batch_size):\n",
    "            train_step(_image, _label)\n",
    "            break\n",
    "        \n",
    "    for test_image, test_label in dataset_test:\n",
    "        test_step(test_image, test_label)\n",
    "        \n",
    "    train_accuracies.append(train_accuracy.result())\n",
    "    test_accuracies.append(test_accuracy.result())    \n",
    "    \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}, spent_time: {} min'\n",
    "    spent_time = time.time() - start_time\n",
    "    print(template.format(epoch + 1, train_loss.result(), train_accuracy.result() * 100, test_loss.result(), test_accuracy.result() * 100, spent_time / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_accuracies, label = 'Train Accuracy')\n",
    "plt.plot(test_accuracies, linestyle = 'dashed', label = 'Test Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('yoloenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa46a74c3be24db11ea83ff4167c221cb75340def6c6e3c75c8e85cfa524936e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
